{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b5bed34",
   "metadata": {},
   "source": [
    "# Lab 2: Search Terms\n",
    "### Creating an autocomplete spell check function from common search terms\n",
    "Created by: Christian Basso\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb5a697",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spellchecker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19652\\4210851111.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spellchecker'"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874366a8",
   "metadata": {},
   "source": [
    "Nearly every modern shopping site uses an autocomplete function to assist in naviagtion around the site and user experience. These functions can be found with many different implimentation structures and data sets. This program will construct an spell check autocomplete function using Direct Supply's DSSI eProcurement system. The DDSI eProcurement system allows for large data sets of common search terms within Direct Supply's website. So, this program is highly tuned around their customers and products. This specific dataset contains searches entered by food-service users over a 60 day period from 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c43291",
   "metadata": {},
   "source": [
    "By using python's built in data structures, search terms can be processed into useful, understandable terms that will be the backbone of our program. The following code imports the raw csv file of searches into a python list. The file is written in utf-8, so the file I/O must be designated to also decode in utf-8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8553bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchTerm,UnitMeasureCode\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searches = []\n",
    "with open ('data/searchTerms.csv', 'r', encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        searches.append(line)\n",
    "f.closed\n",
    "print(searches[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f300372",
   "metadata": {},
   "source": [
    "Within this data set, some spaces are included before, after, and inside words. Additionally, some values have web spaces, which show up as \"%20\" in string form. The following code removes web spaces and redundant spaces then each splits multi word search into single token lists. These token lists are put into a new list.\n",
    "\n",
    "After each search term, there is as measurement unit that is not needed for this program. So, the two unit and comma are removed before it is split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85269780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cottage cheese\n",
      "['cottage', 'cheese']\n",
      "['potato', '3/8']\n"
     ]
    }
   ],
   "source": [
    "removed_code = []\n",
    "split_searches = []\n",
    "\n",
    "for i in searches:\n",
    "    removed_code.append(i.strip()[:-3])\n",
    "    \n",
    "print(removed_code[5345])\n",
    "\n",
    "for i in removed_code:\n",
    "    split_searches.append(i.replace(\"%20\", \" \").split(\" \"))\n",
    "    \n",
    "print(split_searches[5345])\n",
    "print(split_searches[1312])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cacafe2",
   "metadata": {},
   "source": [
    "Beyond just spaces, this set of data contains punctuation and spelling errors. In the following functions the search tokens will be addressed and cleaned in preperation to be added to a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f0d51",
   "metadata": {},
   "source": [
    "The following function cleans the searches for punctuation. This function omits empty searches if removing a punctuation character results in an empty search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "220714dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punct():\n",
    "    punct_searches = []\n",
    "    remove = [\".\", \",\", \"/\", \"?\", \"!\", \"$\", \"@\", \"&\", \"*\", \"(\", \")\", \"#\", \"%\", \"^\", \"-\", \"_\"]\n",
    "    for i in split_searches:\n",
    "        l = []\n",
    "        for j in i:\n",
    "            temp = j\n",
    "            for k in remove:\n",
    "                temp = temp.replace(k, \"\")\n",
    "            if temp != '':\n",
    "                l.append(temp)\n",
    "        punct_searches.append(l)\n",
    "    return punct_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1a0f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potato']\n",
      "['cottage', 'cheese']\n"
     ]
    }
   ],
   "source": [
    "punct_searches = clean_punct()\n",
    "print(clean_searches[1312])\n",
    "print(clean_searches[5345])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd0072a",
   "metadata": {},
   "source": [
    "The next function cleans the searches of numbers. This function also omits empty searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ecbea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_num():\n",
    "    num_searches = []\n",
    "    remove = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "    for i in punct_searches:\n",
    "        l = []\n",
    "        for j in i:\n",
    "            temp = j\n",
    "            for k in remove:\n",
    "                temp = temp.replace(k, \"\")\n",
    "            if temp != '':\n",
    "                l.append(temp)\n",
    "        num_searches.append(l)\n",
    "    return num_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "669a32b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potato']\n",
      "['cottage', 'cheese']\n"
     ]
    }
   ],
   "source": [
    "clean_searches = clean_num()\n",
    "print(clean_searches[1312])\n",
    "print(clean_searches[5345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20010a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
